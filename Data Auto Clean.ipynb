{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from timeit import default_timer as timer\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from math import isnan\n",
        "from sklearn import preprocessing\n",
        "from sklearn.impute import KNNImputer, SimpleImputer\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from loguru import logger\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "'''\n",
        "Modules are used by the AutoClean pipeline for data cleaning and preprocessing.\n",
        "'''\n",
        "\n",
        "class MissingValues:\n",
        "\n",
        "    def handle(self, df, _n_neighbors=3):\n",
        "        # function for handling missing values in the data\n",
        "        if self.missing_num or self.missing_categ:\n",
        "            logger.info('Started handling of missing values...', str(self.missing_num).upper())\n",
        "            start = timer()\n",
        "            self.count_missing = df.isna().sum().sum()\n",
        "\n",
        "            if self.count_missing != 0:\n",
        "                logger.info('Found a total of {} missing value(s)', self.count_missing)\n",
        "                df = df.dropna(how='all')\n",
        "                df.reset_index(drop=True)\n",
        "                \n",
        "                if self.missing_num: # numeric data\n",
        "                    logger.info('Started handling of NUMERICAL missing values... Method: \"{}\"', str(self.missing_num).upper())\n",
        "                    # automated handling\n",
        "                    if self.missing_num == 'auto': \n",
        "                        self.missing_num = 'linreg'\n",
        "                        lr = LinearRegression()\n",
        "                        df = MissingValues._lin_regression_impute(self, df, lr)\n",
        "                        self.missing_num = 'knn'\n",
        "                        imputer = KNNImputer(n_neighbors=_n_neighbors)\n",
        "                        df = MissingValues._impute(self, df, imputer, type='num')\n",
        "                    # linear regression imputation\n",
        "                    elif self.missing_num == 'linreg':\n",
        "                        lr = LinearRegression()\n",
        "                        df = MissingValues._lin_regression_impute(self, df, lr)\n",
        "                    # knn imputation\n",
        "                    elif self.missing_num == 'knn':\n",
        "                        imputer = KNNImputer(n_neighbors=_n_neighbors)\n",
        "                        df = MissingValues._impute(self, df, imputer, type='num')\n",
        "                    # mean, median or mode imputation\n",
        "                    elif self.missing_num in ['mean', 'median', 'most_frequent']:\n",
        "                        imputer = SimpleImputer(strategy=self.missing_num)\n",
        "                        df = MissingValues._impute(self, df, imputer, type='num')\n",
        "                    # delete missing values\n",
        "                    elif self.missing_num == 'delete':\n",
        "                        df = MissingValues._delete(self, df, type='num')\n",
        "                        logger.debug('Deletion of {} NUMERIC missing value(s) succeeded', self.count_missing-df.isna().sum().sum())      \n",
        "\n",
        "                if self.missing_categ: # categorical data\n",
        "                    logger.info('Started handling of CATEGORICAL missing values... Method: \"{}\"', str(self.missing_categ).upper())\n",
        "                    # automated handling\n",
        "                    if self.missing_categ == 'auto':\n",
        "                        self.missing_categ = 'logreg'\n",
        "                        lr = LogisticRegression()\n",
        "                        df = MissingValues._log_regression_impute(self, df, lr)\n",
        "                        self.missing_categ = 'knn'\n",
        "                        imputer = KNNImputer(n_neighbors=_n_neighbors)\n",
        "                        df = MissingValues._impute(self, df, imputer, type='categ')\n",
        "                    elif self.missing_categ == 'logreg':\n",
        "                        lr = LogisticRegression()\n",
        "                        df = MissingValues._log_regression_impute(self, df, lr)\n",
        "                    # knn imputation\n",
        "                    elif self.missing_categ == 'knn':\n",
        "                        imputer = KNNImputer(n_neighbors=_n_neighbors)\n",
        "                        df = MissingValues._impute(self, df, imputer, type='categ')  \n",
        "                    # mode imputation\n",
        "                    elif self.missing_categ == 'most_frequent':\n",
        "                        imputer = SimpleImputer(strategy=self.missing_categ)\n",
        "                        df = MissingValues._impute(self, df, imputer, type='categ')\n",
        "                    # delete missing values                    \n",
        "                    elif self.missing_categ == 'delete':\n",
        "                        df = MissingValues._delete(self, df, type='categ')\n",
        "                        logger.debug('Deletion of {} CATEGORICAL missing value(s) succeeded', self.count_missing-df.isna().sum().sum())\n",
        "            else:\n",
        "                logger.debug('{} missing values found', self.count_missing)\n",
        "            end = timer()\n",
        "            logger.info('Completed handling of missing values in {} seconds', round(end-start, 6))  \n",
        "        else:\n",
        "            logger.info('Skipped handling of missing values')\n",
        "        return df\n",
        "\n",
        "    def _impute(self, df, imputer, type):\n",
        "        # function for imputing missing values in the data\n",
        "        cols_num = df.select_dtypes(include=np.number).columns \n",
        "\n",
        "        if type == 'num':\n",
        "            # numerical features\n",
        "            for feature in df.columns: \n",
        "                if feature in cols_num:\n",
        "                    if df[feature].isna().sum().sum() != 0:\n",
        "                        try:\n",
        "                            df_imputed = pd.DataFrame(imputer.fit_transform(np.array(df[feature]).reshape(-1, 1)))\n",
        "                            counter = df[feature].isna().sum().sum() - df_imputed.isna().sum().sum()\n",
        "\n",
        "                            if (df[feature].fillna(-9999) % 1  == 0).all():\n",
        "                                df[feature] = df_imputed\n",
        "                                # round back to INTs, if original data were INTs\n",
        "                                df[feature] = df[feature].round()\n",
        "                                df[feature] = df[feature].astype('Int64')                                        \n",
        "                            else:\n",
        "                                df[feature] = df_imputed\n",
        "                            if counter != 0:\n",
        "                                logger.debug('{} imputation of {} value(s) succeeded for feature \"{}\"', str(self.missing_num).upper(), counter, feature)\n",
        "                        except:\n",
        "                            logger.warning('{} imputation failed for feature \"{}\"', str(self.missing_num).upper(), feature)\n",
        "        else:\n",
        "            # categorical features\n",
        "            for feature in df.columns:\n",
        "                if feature not in cols_num:\n",
        "                    if df[feature].isna().sum()!= 0:\n",
        "                        try:\n",
        "                            mapping = dict()\n",
        "                            mappings = {k: i for i, k in enumerate(df[feature].dropna().unique(), 0)}\n",
        "                            mapping[feature] = mappings\n",
        "                            df[feature] = df[feature].map(mapping[feature])\n",
        "\n",
        "                            df_imputed = pd.DataFrame(imputer.fit_transform(np.array(df[feature]).reshape(-1, 1)), columns=[feature])    \n",
        "                            counter = sum(1 for i, j in zip(list(df_imputed[feature]), list(df[feature])) if i != j)\n",
        "\n",
        "                            # round to integers before mapping back to original values\n",
        "                            df[feature] = df_imputed\n",
        "                            df[feature] = df[feature].round()\n",
        "                            df[feature] = df[feature].astype('Int64')  \n",
        "\n",
        "                            # map values back to original\n",
        "                            mappings_inv = {v: k for k, v in mapping[feature].items()}\n",
        "                            df[feature] = df[feature].map(mappings_inv)\n",
        "                            if counter != 0:\n",
        "                                logger.debug('{} imputation of {} value(s) succeeded for feature \"{}\"', self.missing_categ.upper(), counter, feature)\n",
        "                        except:\n",
        "                            logger.warning('{} imputation failed for feature \"{}\"', str(self.missing_categ).upper(), feature)\n",
        "        return df\n",
        "\n",
        "    def _lin_regression_impute(self, df, model):\n",
        "        # function for predicting missing values with linear regression\n",
        "        cols_num = df.select_dtypes(include=np.number).columns\n",
        "        mapping = dict()\n",
        "        for feature in df.columns:\n",
        "            if feature not in cols_num:\n",
        "                # create label mapping for categorical feature values\n",
        "                mappings = {k: i for i, k in enumerate(df[feature])}\n",
        "                mapping[feature] = mappings\n",
        "                df[feature] = df[feature].map(mapping[feature])\n",
        "        for feature in cols_num: \n",
        "                try:\n",
        "                    test_df = df[df[feature].isnull()==True].dropna(subset=[x for x in df.columns if x != feature])\n",
        "                    train_df = df[df[feature].isnull()==False].dropna(subset=[x for x in df.columns if x != feature])\n",
        "                    if len(test_df.index) != 0:\n",
        "                        pipe = make_pipeline(StandardScaler(), model)\n",
        "\n",
        "                        y = np.log(train_df[feature]) # log-transform the data\n",
        "                        X_train = train_df.drop(feature, axis=1)\n",
        "                        test_df.drop(feature, axis=1, inplace=True)\n",
        "                        \n",
        "                        try:\n",
        "                            model = pipe.fit(X_train, y)\n",
        "                        except:\n",
        "                            y = train_df[feature] # use non-log-transformed data\n",
        "                            model = pipe.fit(X_train, y)\n",
        "                        if (y == train_df[feature]).all():\n",
        "                            pred = model.predict(test_df)\n",
        "                        else:\n",
        "                            pred = np.exp(model.predict(test_df)) # predict values\n",
        "\n",
        "                        test_df[feature]= pred\n",
        "\n",
        "                        if (df[feature].fillna(-9999) % 1  == 0).all():\n",
        "                            # round back to INTs, if original data were INTs\n",
        "                            test_df[feature] = test_df[feature].round()\n",
        "                            test_df[feature] = test_df[feature].astype('Int64')\n",
        "                            df[feature].update(test_df[feature])                          \n",
        "                        else:\n",
        "                            df[feature].update(test_df[feature])  \n",
        "                        logger.debug('LINREG imputation of {} value(s) succeeded for feature \"{}\"', len(pred), feature)\n",
        "                except:\n",
        "                    logger.warning('LINREG imputation failed for feature \"{}\"', feature)\n",
        "        for feature in df.columns: \n",
        "            try:   \n",
        "                # map categorical feature values back to original\n",
        "                mappings_inv = {v: k for k, v in mapping[feature].items()}\n",
        "                df[feature] = df[feature].map(mappings_inv)\n",
        "            except:\n",
        "                pass\n",
        "        return df\n",
        "\n",
        "    def _log_regression_impute(self, df, model):\n",
        "        # function for predicting missing values with logistic regression\n",
        "        cols_num = df.select_dtypes(include=np.number).columns\n",
        "        mapping = dict()\n",
        "        for feature in df.columns:\n",
        "            if feature not in cols_num:\n",
        "                # create label mapping for categorical feature values\n",
        "                mappings = {k: i for i, k in enumerate(df[feature])} #.dropna().unique(), 0)}\n",
        "                mapping[feature] = mappings\n",
        "                df[feature] = df[feature].map(mapping[feature])\n",
        "\n",
        "        target_cols = [x for x in df.columns if x not in cols_num]\n",
        "            \n",
        "        for feature in df.columns: \n",
        "            if feature in target_cols:\n",
        "                try:\n",
        "                    test_df = df[df[feature].isnull()==True].dropna(subset=[x for x in df.columns if x != feature])\n",
        "                    train_df = df[df[feature].isnull()==False].dropna(subset=[x for x in df.columns if x != feature])\n",
        "                    if len(test_df.index) != 0:\n",
        "                        pipe = make_pipeline(StandardScaler(), model)\n",
        "\n",
        "                        y = train_df[feature]\n",
        "                        train_df.drop(feature, axis=1, inplace=True)\n",
        "                        test_df.drop(feature, axis=1, inplace=True)\n",
        "\n",
        "                        model = pipe.fit(train_df, y)\n",
        "                        \n",
        "                        pred = model.predict(test_df) # predict values\n",
        "                        test_df[feature]= pred\n",
        "\n",
        "                        if (df[feature].fillna(-9999) % 1  == 0).all():\n",
        "                            # round back to INTs, if original data were INTs\n",
        "                            test_df[feature] = test_df[feature].round()\n",
        "                            test_df[feature] = test_df[feature].astype('Int64')\n",
        "                            df[feature].update(test_df[feature])                             \n",
        "                        logger.debug('LOGREG imputation of {} value(s) succeeded for feature \"{}\"', len(pred), feature)\n",
        "                except:\n",
        "                    logger.warning('LOGREG imputation failed for feature \"{}\"', feature)\n",
        "        for feature in df.columns: \n",
        "            try:\n",
        "                # map categorical feature values back to original\n",
        "                mappings_inv = {v: k for k, v in mapping[feature].items()}\n",
        "                df[feature] = df[feature].map(mappings_inv)\n",
        "            except:\n",
        "                pass     \n",
        "        return df\n",
        "\n",
        "    def _delete(self, df, type):\n",
        "        # function for deleting missing values\n",
        "        cols_num = df.select_dtypes(include=np.number).columns \n",
        "        if type == 'num':\n",
        "            # numerical features\n",
        "            for feature in df.columns: \n",
        "                if feature in cols_num:\n",
        "                    df = df.dropna(subset=[feature])\n",
        "                    df.reset_index(drop=True)\n",
        "        else:\n",
        "            # categorical features\n",
        "            for feature in df.columns:\n",
        "                if feature not in cols_num:\n",
        "                    df = df.dropna(subset=[feature])\n",
        "                    df.reset_index(drop=True)\n",
        "        return df                    \n",
        "\n",
        "class Outliers:\n",
        "\n",
        "    def handle(self, df):\n",
        "        # function for handling of outliers in the data\n",
        "        if self.outliers:\n",
        "            logger.info('Started handling of outliers... Method: \"{}\"', str(self.outliers).upper())\n",
        "            start = timer()  \n",
        "\n",
        "            if self.outliers in ['auto', 'winz']:  \n",
        "                df = Outliers._winsorization(self, df)\n",
        "            elif self.outliers == 'delete':\n",
        "                df = Outliers._delete(self, df)\n",
        "            \n",
        "            end = timer()\n",
        "            logger.info('Completed handling of outliers in {} seconds', round(end-start, 6))\n",
        "        else:\n",
        "            logger.info('Skipped handling of outliers')\n",
        "        return df     \n",
        "\n",
        "    def _winsorization(self, df):\n",
        "        # function for outlier winsorization\n",
        "        cols_num = df.select_dtypes(include=np.number).columns    \n",
        "        for feature in cols_num:           \n",
        "            counter = 0\n",
        "            # compute outlier bounds\n",
        "            lower_bound, upper_bound = Outliers._compute_bounds(self, df, feature)    \n",
        "            for row_index, row_val in enumerate(df[feature]):\n",
        "                if row_val < lower_bound or row_val > upper_bound:\n",
        "                    if row_val < lower_bound:\n",
        "                        if (df[feature].fillna(-9999) % 1  == 0).all():\n",
        "                                df.loc[row_index, feature] = lower_bound\n",
        "                                df[feature] = df[feature].astype(int) \n",
        "                        else:    \n",
        "                            df.loc[row_index, feature] = lower_bound\n",
        "                        counter += 1\n",
        "                    else:\n",
        "                        if (df[feature].fillna(-9999) % 1  == 0).all():\n",
        "                            df.loc[row_index, feature] = upper_bound\n",
        "                            df[feature] = df[feature].astype(int) \n",
        "                        else:\n",
        "                            df.loc[row_index, feature] = upper_bound\n",
        "                        counter += 1\n",
        "            if counter != 0:\n",
        "                logger.debug('Outlier imputation of {} value(s) succeeded for feature \"{}\"', counter, feature)        \n",
        "        return df\n",
        "\n",
        "    def _delete(self, df):\n",
        "        # function for deleting outliers in the data\n",
        "        cols_num = df.select_dtypes(include=np.number).columns    \n",
        "        for feature in cols_num:\n",
        "            counter = 0\n",
        "            lower_bound, upper_bound = Outliers._compute_bounds(self, df, feature)    \n",
        "            # delete observations containing outliers            \n",
        "            for row_index, row_val in enumerate(df[feature]):\n",
        "                if row_val < lower_bound or row_val > upper_bound:\n",
        "                    df = df.drop(row_index)\n",
        "                    counter +=1\n",
        "            df = df.reset_index(drop=True)\n",
        "            if counter != 0:\n",
        "                logger.debug('Deletion of {} outliers succeeded for feature \"{}\"', counter, feature)\n",
        "        return df\n",
        "\n",
        "    def _compute_bounds(self, df, feature):\n",
        "        # function that computes the lower and upper bounds for finding outliers in the data\n",
        "        featureSorted = sorted(df[feature])\n",
        "        \n",
        "        q1, q3 = np.percentile(featureSorted, [25, 75])\n",
        "        iqr = q3 - q1\n",
        "\n",
        "        lb = q1 - (self.outlier_param * iqr) \n",
        "        ub = q3 + (self.outlier_param * iqr) \n",
        "\n",
        "        return lb, ub    \n",
        "\n",
        "class Adjust:\n",
        "\n",
        "    def convert_datetime(self, df):\n",
        "        # function for extracting of datetime values in the data\n",
        "        if self.extract_datetime:\n",
        "            logger.info('Started conversion of DATETIME features... Granularity: {}', self.extract_datetime)\n",
        "            start = timer()\n",
        "            cols = set(df.columns) ^ set(df.select_dtypes(include=np.number).columns) \n",
        "            for feature in cols: \n",
        "                try:\n",
        "                    # convert features encoded as strings to type datetime ['D','M','Y','h','m','s']\n",
        "                    df[feature] = pd.to_datetime(df[feature], infer_datetime_format=True)\n",
        "                    try:\n",
        "                        df['Day'] = pd.to_datetime(df[feature]).dt.day\n",
        "\n",
        "                        if self.extract_datetime in ['auto', 'M','Y','h','m','s']:\n",
        "                            df['Month'] = pd.to_datetime(df[feature]).dt.month\n",
        "\n",
        "                            if self.extract_datetime in ['auto', 'Y','h','m','s']:\n",
        "                                df['Year'] = pd.to_datetime(df[feature]).dt.year\n",
        "\n",
        "                                if self.extract_datetime in ['auto', 'h','m','s']:\n",
        "                                    df['Hour'] = pd.to_datetime(df[feature]).dt.hour\n",
        "\n",
        "                                    if self.extract_datetime in ['auto', 'm','s']:\n",
        "                                        df['Minute'] = pd.to_datetime(df[feature]).dt.minute\n",
        "\n",
        "                                        if self.extract_datetime in ['auto', 's']:\n",
        "                                            df['Sec'] = pd.to_datetime(df[feature]).dt.second\n",
        "                        \n",
        "                        logger.debug('Conversion to DATETIME succeeded for feature \"{}\"', feature)\n",
        "\n",
        "                        try: \n",
        "                            # check if entries for the extracted dates/times are non-NULL, otherwise drop\n",
        "                            if (df['Hour'] == 0).all() and (df['Minute'] == 0).all() and (df['Sec'] == 0).all():\n",
        "                                df.drop('Hour', inplace = True, axis =1 )\n",
        "                                df.drop('Minute', inplace = True, axis =1 )\n",
        "                                df.drop('Sec', inplace = True, axis =1 )\n",
        "                            elif (df['Day'] == 0).all() and (df['Month'] == 0).all() and (df['Year'] == 0).all():\n",
        "                                df.drop('Day', inplace = True, axis =1 )\n",
        "                                df.drop('Month', inplace = True, axis =1 )\n",
        "                                df.drop('Year', inplace = True, axis =1 )   \n",
        "                        except:\n",
        "                            pass          \n",
        "                    except:\n",
        "                        # feature cannot be converted to datetime\n",
        "                        logger.warning('Conversion to DATETIME failed for \"{}\"', feature)\n",
        "                except:\n",
        "                    pass\n",
        "            end = timer()\n",
        "            logger.info('Completed conversion of DATETIME features in {} seconds', round(end-start, 4))\n",
        "        else:\n",
        "            logger.info('Skipped datetime feature conversion')\n",
        "        return df\n",
        "\n",
        "    def round_values(self, df, input_data):\n",
        "        # function that checks datatypes of features and converts them if necessary\n",
        "        if self.duplicates or self.missing_num or self.missing_categ or self.outliers or self.encode_categ or self.extract_datetime:\n",
        "            logger.info('Started feature type conversion...')\n",
        "            start = timer()\n",
        "            counter = 0\n",
        "            cols_num = df.select_dtypes(include=np.number).columns\n",
        "            for feature in cols_num:\n",
        "                    # check if all values are integers\n",
        "                    if (df[feature].fillna(-9999) % 1  == 0).all():\n",
        "                        try:\n",
        "                            # encode FLOATs with only 0 as decimals to INT\n",
        "                            df[feature] = df[feature].astype('Int64')\n",
        "                            counter += 1\n",
        "                            logger.debug('Conversion to type INT succeeded for feature \"{}\"', feature)\n",
        "                        except:\n",
        "                            logger.warning('Conversion to type INT failed for feature \"{}\"', feature)\n",
        "                    else:\n",
        "                        try:\n",
        "                            df[feature] = df[feature].astype(float)\n",
        "                            # round the number of decimals of FLOATs back to original\n",
        "                            dec = None\n",
        "                            for value in input_data[feature]:\n",
        "                                try:\n",
        "                                    if dec == None:\n",
        "                                        dec = str(value)[::-1].find('.')\n",
        "                                    else:\n",
        "                                        if str(value)[::-1].find('.') > dec:\n",
        "                                            dec = str(value)[::-1].find('.')\n",
        "                                except:\n",
        "                                    pass\n",
        "                            df[feature] = df[feature].round(decimals = dec)\n",
        "                            counter += 1\n",
        "                            logger.debug('Conversion to type FLOAT succeeded for feature \"{}\"', feature)\n",
        "                        except:\n",
        "                            logger.warning('Conversion to type FLOAT failed for feature \"{}\"', feature)\n",
        "            end = timer()\n",
        "            logger.info('Completed feature type conversion for {} feature(s) in {} seconds', counter, round(end-start, 6))\n",
        "        else:\n",
        "            logger.info('Skipped feature type conversion')\n",
        "        return df\n",
        "\n",
        "class EncodeCateg:\n",
        "\n",
        "    def handle(self, df):\n",
        "        # function for encoding of categorical features in the data\n",
        "        if self.encode_categ:\n",
        "            if not isinstance(self.encode_categ, list):\n",
        "                self.encode_categ = ['auto']\n",
        "            # select non numeric features\n",
        "            cols_categ = set(df.columns) ^ set(df.select_dtypes(include=np.number).columns) \n",
        "            # check if all columns should be encoded\n",
        "            if len(self.encode_categ) == 1:\n",
        "                target_cols = cols_categ # encode ALL columns\n",
        "            else:\n",
        "                target_cols = self.encode_categ[1] # encode only specific columns\n",
        "            logger.info('Started encoding categorical features... Method: \"{}\"', str(self.encode_categ[0]).upper())\n",
        "            start = timer()\n",
        "            for feature in target_cols:\n",
        "                if feature in cols_categ:\n",
        "                    # columns are column names\n",
        "                    feature = feature\n",
        "                else:\n",
        "                    # columns are indexes\n",
        "                    feature = df.columns[feature]\n",
        "                try:\n",
        "                    # skip encoding of datetime features\n",
        "                    pd.to_datetime(df[feature])\n",
        "                    logger.debug('Skipped encoding for DATETIME feature \"{}\"', feature)\n",
        "                except:\n",
        "                    try:\n",
        "                        if self.encode_categ[0] == 'auto':\n",
        "                            # ONEHOT encode if not more than 10 unique values to encode\n",
        "                            if df[feature].nunique() <=10:\n",
        "                                df = EncodeCateg._to_onehot(self, df, feature)\n",
        "                                logger.debug('Encoding to ONEHOT succeeded for feature \"{}\"', feature)\n",
        "                            # LABEL encode if not more than 20 unique values to encode\n",
        "                            elif df[feature].nunique() <=20:\n",
        "                                df = EncodeCateg._to_label(self, df, feature)\n",
        "                                logger.debug('Encoding to LABEL succeeded for feature \"{}\"', feature)\n",
        "                            # skip encoding if more than 20 unique values to encode\n",
        "                            else:\n",
        "                                logger.debug('Encoding skipped for feature \"{}\"', feature)   \n",
        "\n",
        "                        elif self.encode_categ[0] == 'onehot':\n",
        "                            df = EncodeCateg._to_onehot(df, feature)\n",
        "                            logger.debug('Encoding to {} succeeded for feature \"{}\"', str(self.encode_categ[0]).upper(), feature)\n",
        "                        elif self.encode_categ[0] == 'label':\n",
        "                            df = EncodeCateg._to_label(df, feature)\n",
        "                            logger.debug('Encoding to {} succeeded for feature \"{}\"', str(self.encode_categ[0]).upper(), feature)      \n",
        "                    except:\n",
        "                        logger.warning('Encoding to {} failed for feature \"{}\"', str(self.encode_categ[0]).upper(), feature)    \n",
        "            end = timer()\n",
        "            logger.info('Completed encoding of categorical features in {} seconds', round(end-start, 6))\n",
        "        else:\n",
        "            logger.info('Skipped encoding of categorical features')\n",
        "        return df\n",
        "\n",
        "    def _to_onehot(self, df, feature, limit=10):  \n",
        "        # function that encodes categorical features to OneHot encodings    \n",
        "        one_hot = pd.get_dummies(df[feature], prefix=feature)\n",
        "        if one_hot.shape[1] > limit:\n",
        "            logger.warning('ONEHOT encoding for feature \"{}\" creates {} new features. Consider LABEL encoding instead.', feature, one_hot.shape[1])\n",
        "        # join the encoded df\n",
        "        df = df.join(one_hot)\n",
        "        return df\n",
        "\n",
        "    def _to_label(self, df, feature):\n",
        "        # function that encodes categorical features to label encodings \n",
        "        le = preprocessing.LabelEncoder()\n",
        "\n",
        "        df[feature + '_lab'] = le.fit_transform(df[feature].values)\n",
        "        mapping = dict(zip(le.classes_, range(len(le.classes_))))\n",
        "        \n",
        "        for key in mapping:\n",
        "            try:\n",
        "                if isnan(key):               \n",
        "                    replace = {mapping[key] : key }\n",
        "                    df[feature].replace(replace, inplace=True)\n",
        "            except:\n",
        "                pass\n",
        "        return df  \n",
        "\n",
        "class Duplicates:\n",
        "\n",
        "    def handle(self, df):\n",
        "        if self.duplicates:\n",
        "            logger.info('Started handling of duplicates... Method: \"{}\"', str(self.duplicates).upper())\n",
        "            start = timer()\n",
        "            original = df.shape\n",
        "            try:\n",
        "                df.drop_duplicates(inplace=True, ignore_index=False)\n",
        "                df = df.reset_index(drop=True)\n",
        "                new = df.shape\n",
        "                count = original[0] - new[0]\n",
        "                if count != 0:\n",
        "                    logger.debug('Deletion of {} duplicate(s) succeeded', count)\n",
        "                else:\n",
        "                    logger.debug('{} missing values found', count)\n",
        "                end = timer()\n",
        "                logger.info('Completed handling of duplicates in {} seconds', round(end-start, 6))\n",
        "\n",
        "            except:\n",
        "                logger.warning('Handling of duplicates failed')        \n",
        "        else:\n",
        "            logger.info('Skipped handling of duplicates')\n",
        "        return df "
      ],
      "metadata": {
        "id": "tMYnAiY5ioIz"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "6gvY-f17gygc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1e27e19-ee30-498e-be28-dacdb6249415"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: py-AutoClean in /usr/local/lib/python3.8/dist-packages (1.1.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from py-AutoClean) (1.21.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from py-AutoClean) (1.3.5)\n",
            "Requirement already satisfied: loguru in /usr/local/lib/python3.8/dist-packages (from py-AutoClean) (0.6.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from py-AutoClean) (1.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->py-AutoClean) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->py-AutoClean) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->py-AutoClean) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->py-AutoClean) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->py-AutoClean) (1.2.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->py-AutoClean) (1.7.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install py-AutoClean\n",
        "import os\n",
        "import sys\n",
        "from timeit import default_timer as timer\n",
        "import pandas as pd\n",
        "from loguru import logger\n",
        "from AutoClean.modules import *\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AutoClean:\n",
        "\n",
        "    def __init__(self, input_data, mode='auto', duplicates=False, missing_num=False, missing_categ=False, encode_categ=False, extract_datetime=False, outliers=False, outlier_param=1.5, logfile=True, verbose=False):  \n",
        "        '''\n",
        "        input_data (dataframe)..........Pandas dataframe\n",
        "        mode (str)......................define in which mode you want to run AutoClean\n",
        "                                        'auto' = sets all parameters to 'auto' and let AutoClean do the data cleaning automatically\n",
        "                                        'manual' = lets you choose which parameters/cleaning steps you want to perform\n",
        "                                        \n",
        "        duplicates (str)................define if duplicates in the data should be handled\n",
        "                                        duplicates are rows where all features are identical\n",
        "                                        'auto' = automated handling, deletes all copies of duplicates except one\n",
        "                                        False = skips this step\n",
        "        missing_num (str)...............define how NUMERICAL missing values are handled\n",
        "                                        'auto' = automated handling\n",
        "                                        'linreg' = uses Linear Regression for predicting missing values\n",
        "                                        'knn' = uses K-NN algorithm for imputation\n",
        "                                        'mean','median' or 'most_frequent' = uses mean/median/mode imputatiom\n",
        "                                        'delete' = deletes observations with missing values\n",
        "                                        False = skips this step\n",
        "        missing_categ (str).............define how CATEGORICAL missing values are handled\n",
        "                                        'auto' = automated handling\n",
        "                                        'logreg' = uses Logistic Regression for predicting missing values\n",
        "                                        'knn' = uses K-NN algorithm for imputation\n",
        "                                        'most_frequent' = uses mode imputatiom\n",
        "                                        'delete' = deletes observations with missing values\n",
        "                                        False = skips this step\n",
        "        encode_categ (list).............encode CATEGORICAL features, takes a list as input\n",
        "                                        ['auto'] = automated encoding\n",
        "                                        ['onehot'] = one-hot-encode all CATEGORICAL features\n",
        "                                        ['label'] = label-encode all categ. features\n",
        "                                        to encode only specific features add the column name or index: ['onehot', ['col1', 2]]\n",
        "                                        False = skips this step\n",
        "        extract_datetime (str)..........define whether DATETIME type features should be extracted into separate features\n",
        "                                        to define granularity set to 'D'= day, 'M'= month, 'Y'= year, 'h'= hour, 'm'= minute or 's'= second\n",
        "                                        False = skips this step\n",
        "        outliers (str)..................define how outliers are handled\n",
        "                                        'winz' = replaces outliers through winsorization\n",
        "                                        'delete' = deletes observations containing outliers\n",
        "                                        oberservations are considered outliers if they are outside the lower and upper bound [Q1-1.5*IQR, Q3+1.5*IQR], where IQR is the interquartile range\n",
        "                                        to set a custom multiplier use the 'outlier_param' parameter\n",
        "                                        False = skips this step\n",
        "        outlier_param (int, float)......define the multiplier for the outlier bounds\n",
        "        logfile (bool)..................define whether to create a logile during the AutoClean process\n",
        "                                        logfile will be saved in working directory as \"autoclean.log\"\n",
        "        verbose (bool)..................define whether AutoClean logs will be printed in console\n",
        "        \n",
        "        OUTPUT (dataframe)..............a cleaned Pandas dataframe, accessible through the 'output' instance\n",
        "        '''\n",
        "        start = timer()\n",
        "        self._initialize_logger(verbose, logfile)\n",
        "        \n",
        "        output_data = input_data.copy()\n",
        "\n",
        "        if mode == 'auto':\n",
        "            duplicates, missing_num, missing_categ, outliers, encode_categ, extract_datetime = 'auto', 'auto', 'auto', 'winz', ['auto'], 's'\n",
        "\n",
        "        self.mode = mode\n",
        "        self.duplicates = duplicates\n",
        "        self.missing_num = missing_num\n",
        "        self.missing_categ = missing_categ\n",
        "        self.outliers = outliers\n",
        "        self.encode_categ = encode_categ\n",
        "        self.extract_datetime = extract_datetime\n",
        "        self.outlier_param = outlier_param\n",
        "        \n",
        "        # validate the input parameters\n",
        "        self._validate_params(output_data, verbose, logfile)\n",
        "        \n",
        "        # initialize our class and start the autoclean process\n",
        "        self.output = self._clean_data(output_data, input_data)  \n",
        "\n",
        "        end = timer()\n",
        "        logger.info('AutoClean process completed in {} seconds', round(end-start, 6))\n",
        "\n",
        "        if not verbose:\n",
        "            print('AutoClean process completed in', round(end-start, 6), 'seconds')\n",
        "        if logfile:\n",
        "            print('Logfile saved to:', os.path.join(os.getcwd(), 'autoclean.log'))\n",
        "\n",
        "    def _initialize_logger(self, verbose, logfile):\n",
        "        # function for initializing the logging process\n",
        "        logger.remove()\n",
        "        if verbose == True:\n",
        "            logger.add(sys.stderr, format='{time:DD-MM-YYYY HH:mm:ss.SS} - {level} - {message}')\n",
        "        if logfile == True:    \n",
        "            logger.add('autoclean.log', mode='w', format='{time:DD-MM-YYYY HH:mm:ss.SS} - {level} - {message}')\n",
        "        return\n",
        "\n",
        "    def _validate_params(self, df, verbose, logfile):\n",
        "        # function for validating the input parameters of the autolean process\n",
        "        logger.info('Started validation of input parameters...')\n",
        "        \n",
        "        if type(df) != pd.core.frame.DataFrame:\n",
        "            raise ValueError('Invalid value for \"df\" parameter.')\n",
        "        if self.mode not in ['manual', 'auto']:\n",
        "            raise ValueError('Invalid value for \"mode\" parameter.')\n",
        "        if self.duplicates not in [False, 'auto']:\n",
        "            raise ValueError('Invalid value for \"duplicates\" parameter.')\n",
        "        if self.missing_num not in [False, 'auto', 'knn', 'mean', 'median', 'most_frequent', 'delete']:\n",
        "            raise ValueError('Invalid value for \"missing_num\" parameter.')\n",
        "        if self.missing_categ not in [False, 'auto', 'knn', 'most_frequent', 'delete']:\n",
        "            raise ValueError('Invalid value for \"missing_categ\" parameter.')\n",
        "        if self.outliers not in [False, 'auto', 'winz', 'delete']:\n",
        "            raise ValueError('Invalid value for \"outliers\" parameter.')\n",
        "        if isinstance(self.encode_categ, list):\n",
        "            if len(self.encode_categ) > 2 and self.encode_categ[0] not in ['auto', 'onehot', 'label']:\n",
        "                raise ValueError('Invalid value for \"encode_categ\" parameter.')\n",
        "            if len(self.encode_categ) == 2:\n",
        "                if not isinstance(self.encode_categ[1], list):\n",
        "                    raise ValueError('Invalid value for \"encode_categ\" parameter.')\n",
        "        else:\n",
        "            if not self.encode_categ in ['auto', False]:\n",
        "                raise ValueError('Invalid value for \"encode_categ\" parameter.')\n",
        "        if not isinstance(self.outlier_param, int) and not isinstance(self.outlier_param, float):\n",
        "            raise ValueError('Invalid value for \"outlier_param\" parameter.')  \n",
        "        if self.extract_datetime not in [False, 'auto', 'D','M','Y','h','m','s']:\n",
        "            raise ValueError('Invalid value for \"extract_datetime\" parameter.')  \n",
        "        if not isinstance(verbose, bool):\n",
        "            raise ValueError('Invalid value for \"verbose\" parameter.')  \n",
        "        if not isinstance(logfile, bool):\n",
        "            raise ValueError('Invalid value for \"logfile\" parameter.')  \n",
        "\n",
        "        logger.info('Completed validation of input parameters')\n",
        "        return\n",
        "            \n",
        "    def _clean_data(self, df, input_data):\n",
        "        # function for starting the autoclean process\n",
        "        df = df.reset_index(drop=True)\n",
        "        df = Duplicates.handle(self, df)\n",
        "        df = MissingValues.handle(self, df)\n",
        "        df = Outliers.handle(self, df)    \n",
        "        df = Adjust.convert_datetime(self, df) \n",
        "        df = EncodeCateg.handle(self, df)     \n",
        "        df = Adjust.round_values(self, df, input_data)\n",
        "        return df "
      ],
      "metadata": {
        "id": "6uN9ZhWrg5Lt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.read_csv('/content/Medical Costs.csv')\n",
        "df1.head(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "0WVNRz3ekXaE",
        "outputId": "a7f8ff6f-febe-413e-a729-8fa0a8b27997"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     age     sex     bmi  life expectancy at birth  children smoker  \\\n",
              "0    NaN  female  27.900                        68         0    yes   \n",
              "1   18.0    male  33.770                        73         1     no   \n",
              "2   28.0    male  33.000                        73         3     no   \n",
              "3   33.0    male  22.705                        73         0     no   \n",
              "4   32.0    male  28.880                        73         0     no   \n",
              "5   31.0  female  25.740                        79         0     no   \n",
              "6   46.0  female  33.440                        79         1     no   \n",
              "7   37.0  female     NaN                        79         3     no   \n",
              "8   37.0    male  29.830                        73         2     no   \n",
              "9   60.0  female  25.840                        79         0     no   \n",
              "10  25.0    male  26.220                        73         0     no   \n",
              "11  62.0  female  26.290                        68         0    yes   \n",
              "12  23.0    male  34.400                        73         0     no   \n",
              "13  56.0  female  39.820                        79         0     no   \n",
              "14  27.0    male  42.130                        61         0    yes   \n",
              "15  19.0    male  24.600                        73         1     no   \n",
              "16  52.0  female  30.780                        79         1     no   \n",
              "17  23.0    male  23.845                        73         0     no   \n",
              "18  56.0    male  40.300                        73         0     no   \n",
              "19  30.0    male  35.300                        61         0    yes   \n",
              "\n",
              "       region      charges  \n",
              "0   southwest  16884.92400  \n",
              "1   southeast   1725.55230  \n",
              "2   southeast   4449.46200  \n",
              "3   northwest  21984.47061  \n",
              "4   northwest   3866.85520  \n",
              "5   southeast   3756.62160  \n",
              "6   southeast   8240.58960  \n",
              "7   northwest          NaN  \n",
              "8   northeast   6406.41070  \n",
              "9   northwest  28923.13692  \n",
              "10  northeast   2721.32080  \n",
              "11  southeast  27808.72510  \n",
              "12  southwest   1826.84300  \n",
              "13  southeast  11090.71780  \n",
              "14  southeast  39611.75770  \n",
              "15  southwest   1837.23700  \n",
              "16  northeast  10797.33620  \n",
              "17  northeast   2395.17155  \n",
              "18  southwest  10602.38500  \n",
              "19  southwest  36837.46700  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3cb32d13-b5a6-43cc-a31d-9e9fe75a5f56\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>life expectancy at birth</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "      <th>charges</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>female</td>\n",
              "      <td>27.900</td>\n",
              "      <td>68</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>southwest</td>\n",
              "      <td>16884.92400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18.0</td>\n",
              "      <td>male</td>\n",
              "      <td>33.770</td>\n",
              "      <td>73</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1725.55230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28.0</td>\n",
              "      <td>male</td>\n",
              "      <td>33.000</td>\n",
              "      <td>73</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>4449.46200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33.0</td>\n",
              "      <td>male</td>\n",
              "      <td>22.705</td>\n",
              "      <td>73</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>21984.47061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32.0</td>\n",
              "      <td>male</td>\n",
              "      <td>28.880</td>\n",
              "      <td>73</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>3866.85520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>31.0</td>\n",
              "      <td>female</td>\n",
              "      <td>25.740</td>\n",
              "      <td>79</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>3756.62160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>46.0</td>\n",
              "      <td>female</td>\n",
              "      <td>33.440</td>\n",
              "      <td>79</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>8240.58960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>37.0</td>\n",
              "      <td>female</td>\n",
              "      <td>NaN</td>\n",
              "      <td>79</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>37.0</td>\n",
              "      <td>male</td>\n",
              "      <td>29.830</td>\n",
              "      <td>73</td>\n",
              "      <td>2</td>\n",
              "      <td>no</td>\n",
              "      <td>northeast</td>\n",
              "      <td>6406.41070</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>60.0</td>\n",
              "      <td>female</td>\n",
              "      <td>25.840</td>\n",
              "      <td>79</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>28923.13692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>25.0</td>\n",
              "      <td>male</td>\n",
              "      <td>26.220</td>\n",
              "      <td>73</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northeast</td>\n",
              "      <td>2721.32080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>62.0</td>\n",
              "      <td>female</td>\n",
              "      <td>26.290</td>\n",
              "      <td>68</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>southeast</td>\n",
              "      <td>27808.72510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>23.0</td>\n",
              "      <td>male</td>\n",
              "      <td>34.400</td>\n",
              "      <td>73</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>southwest</td>\n",
              "      <td>1826.84300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>56.0</td>\n",
              "      <td>female</td>\n",
              "      <td>39.820</td>\n",
              "      <td>79</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>11090.71780</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>27.0</td>\n",
              "      <td>male</td>\n",
              "      <td>42.130</td>\n",
              "      <td>61</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>southeast</td>\n",
              "      <td>39611.75770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>19.0</td>\n",
              "      <td>male</td>\n",
              "      <td>24.600</td>\n",
              "      <td>73</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>southwest</td>\n",
              "      <td>1837.23700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>52.0</td>\n",
              "      <td>female</td>\n",
              "      <td>30.780</td>\n",
              "      <td>79</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>northeast</td>\n",
              "      <td>10797.33620</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>23.0</td>\n",
              "      <td>male</td>\n",
              "      <td>23.845</td>\n",
              "      <td>73</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northeast</td>\n",
              "      <td>2395.17155</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>56.0</td>\n",
              "      <td>male</td>\n",
              "      <td>40.300</td>\n",
              "      <td>73</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>southwest</td>\n",
              "      <td>10602.38500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>30.0</td>\n",
              "      <td>male</td>\n",
              "      <td>35.300</td>\n",
              "      <td>61</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>southwest</td>\n",
              "      <td>36837.46700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3cb32d13-b5a6-43cc-a31d-9e9fe75a5f56')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3cb32d13-b5a6-43cc-a31d-9e9fe75a5f56 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3cb32d13-b5a6-43cc-a31d-9e9fe75a5f56');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from AutoClean import autoclean\n",
        "df2 = pd.read_csv('/content/Medical Costs.csv')\n",
        "pipeline = AutoClean(df2)\n",
        "\n",
        "pipeline.output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "nlrxxPcDhk-A",
        "outputId": "4b221be1-1276-4733-989c-65989ce6af15"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AutoClean process completed in 0.447287 seconds\n",
            "Logfile saved to: /content/autoclean.log\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      age     sex     bmi  life expectancy at birth  children smoker  \\\n",
              "0      25  female  27.900                        68         0    yes   \n",
              "1      18    male  33.770                        73         1     no   \n",
              "2      28    male  33.000                        73         3     no   \n",
              "3      33    male  22.705                        73         0     no   \n",
              "4      32    male  28.880                        73         0     no   \n",
              "...   ...     ...     ...                       ...       ...    ...   \n",
              "1332   50    male  30.337                        73         3     no   \n",
              "1333   18  female  28.826                        79         0     no   \n",
              "1334   18  female  28.664                        79         0     no   \n",
              "1335   21  female  28.669                        79         0     no   \n",
              "1336   61  female  27.913                        68         0    yes   \n",
              "\n",
              "         region      charges  region_northeast  region_northwest  \\\n",
              "0     southwest  16884.92400                 0                 0   \n",
              "1     southeast   1725.55230                 0                 0   \n",
              "2     southeast   4449.46200                 0                 0   \n",
              "3     northwest  21984.47061                 0                 1   \n",
              "4     northwest   3866.85520                 0                 1   \n",
              "...         ...          ...               ...               ...   \n",
              "1332  northwest  10600.54830                 0                 1   \n",
              "1333  northeast   2205.98080                 1                 0   \n",
              "1334  southeast   1629.83350                 0                 0   \n",
              "1335  southwest   2007.94500                 0                 0   \n",
              "1336  northwest  29141.36030                 0                 1   \n",
              "\n",
              "      region_southeast  region_southwest  sex_female  sex_male  smoker_no  \\\n",
              "0                    0                 1           1         0          0   \n",
              "1                    1                 0           0         1          1   \n",
              "2                    1                 0           0         1          1   \n",
              "3                    0                 0           0         1          1   \n",
              "4                    0                 0           0         1          1   \n",
              "...                ...               ...         ...       ...        ...   \n",
              "1332                 0                 0           0         1          1   \n",
              "1333                 0                 0           1         0          1   \n",
              "1334                 1                 0           1         0          1   \n",
              "1335                 0                 1           1         0          1   \n",
              "1336                 0                 0           1         0          0   \n",
              "\n",
              "      smoker_yes  \n",
              "0              1  \n",
              "1              0  \n",
              "2              0  \n",
              "3              0  \n",
              "4              0  \n",
              "...          ...  \n",
              "1332           0  \n",
              "1333           0  \n",
              "1334           0  \n",
              "1335           0  \n",
              "1336           1  \n",
              "\n",
              "[1337 rows x 16 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-54c408cf-d341-4934-8d81-1ced017dcadd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>life expectancy at birth</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "      <th>charges</th>\n",
              "      <th>region_northeast</th>\n",
              "      <th>region_northwest</th>\n",
              "      <th>region_southeast</th>\n",
              "      <th>region_southwest</th>\n",
              "      <th>sex_female</th>\n",
              "      <th>sex_male</th>\n",
              "      <th>smoker_no</th>\n",
              "      <th>smoker_yes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>25</td>\n",
              "      <td>female</td>\n",
              "      <td>27.900</td>\n",
              "      <td>68</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>southwest</td>\n",
              "      <td>16884.92400</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>male</td>\n",
              "      <td>33.770</td>\n",
              "      <td>73</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1725.55230</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>male</td>\n",
              "      <td>33.000</td>\n",
              "      <td>73</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>4449.46200</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>male</td>\n",
              "      <td>22.705</td>\n",
              "      <td>73</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>21984.47061</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>male</td>\n",
              "      <td>28.880</td>\n",
              "      <td>73</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>3866.85520</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1332</th>\n",
              "      <td>50</td>\n",
              "      <td>male</td>\n",
              "      <td>30.337</td>\n",
              "      <td>73</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>10600.54830</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1333</th>\n",
              "      <td>18</td>\n",
              "      <td>female</td>\n",
              "      <td>28.826</td>\n",
              "      <td>79</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northeast</td>\n",
              "      <td>2205.98080</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1334</th>\n",
              "      <td>18</td>\n",
              "      <td>female</td>\n",
              "      <td>28.664</td>\n",
              "      <td>79</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1629.83350</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1335</th>\n",
              "      <td>21</td>\n",
              "      <td>female</td>\n",
              "      <td>28.669</td>\n",
              "      <td>79</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>southwest</td>\n",
              "      <td>2007.94500</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1336</th>\n",
              "      <td>61</td>\n",
              "      <td>female</td>\n",
              "      <td>27.913</td>\n",
              "      <td>68</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>northwest</td>\n",
              "      <td>29141.36030</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1337 rows × 16 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-54c408cf-d341-4934-8d81-1ced017dcadd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-54c408cf-d341-4934-8d81-1ced017dcadd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-54c408cf-d341-4934-8d81-1ced017dcadd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    }
  ]
}